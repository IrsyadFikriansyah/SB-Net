{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- this file is used for making train data (1) and test data (5) from sensor 1, 2, 5, 9, and 13\n",
    "- The training data will consist of an accumulation of 70% from each sensor\n",
    "- the test data will consist of 30% from each sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv('1/capture20110810.binetflow')\n",
    "df_2 = pd.read_csv('2/capture20110811.binetflow')\n",
    "df_5 = pd.read_csv('5/capture20110815-2.binetflow')\n",
    "df_9 = pd.read_csv('9/capture20110817.binetflow')\n",
    "df_13 = pd.read_csv('13/capture20110815-3.binetflow')\n",
    "\n",
    "df = [df_1, df_2, df_5, df_9, df_13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2824636\t1977245\t847390\n",
      "1808122\t1265685\t542436\n",
      "129832\t90882\t38949\n",
      "2087508\t1461255\t626252\n",
      "1925149\t1347604\t577544\n",
      "train_sum 6142671\n",
      "test_sum 2632571\n"
     ]
    }
   ],
   "source": [
    "train_sum = 0\n",
    "test_sum = 0\n",
    "\n",
    "for i in df:\n",
    "    size = len(i)\n",
    "    train_sum += int(size * 0.7)\n",
    "    test_sum += int(size * 0.3)\n",
    "    print(f\"{size}\\t{int(size * 0.7)}\\t{int(size * 0.3)}\")\n",
    "\n",
    "print('train_sum', train_sum)\n",
    "print('test_sum', test_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplify the label column\n",
    "def categorize_label(label):\n",
    "    label = str(label).lower()\n",
    "    if 'botnet' in label:\n",
    "        if 'spam' in label:\n",
    "            return 'botnet_spam'\n",
    "        else:\n",
    "            return 'botnet'\n",
    "    else:\n",
    "        return 'normal'\n",
    "\n",
    "# Apply the function to the 'Label' column\n",
    "for i in df:\n",
    "    i['Label'] = i['Label'].apply(categorize_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to make the data simpler, (following my paper) this code will remove the unecessary feature such as:\n",
    "- dTos\n",
    "- sTos\n",
    "- ActivityLabel (only in NCC-2)\n",
    "- BotnetName (only in NCC-2)\n",
    "- SensorId (only in NCC-2)\n",
    "- StartTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(len(df)):\n",
    "    df[index] = df[index].drop(\n",
    "        columns=['dTos', 'sTos', 'ActivityLabel', 'BotnetName', 'SensorId', 'StartTime'], \n",
    "        errors='ignore'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_df = []\n",
    "botnet_df = []\n",
    "botnet_spam_df = []\n",
    "\n",
    "for i in df:\n",
    "    normal_df.append(i[i['Label'] == 'normal'])\n",
    "    botnet_df.append(i[i['Label'] == 'botnet'])\n",
    "    botnet_spam_df.append(i[i['Label'] == 'botnet_spam'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_train, normal_test = [], []\n",
    "botnet_train, botnet_test = [], []\n",
    "botnet_spam_train, botnet_spam_test = [], []\n",
    "\n",
    "for a, b, c in zip(normal_df, botnet_df, botnet_spam_df):\n",
    "    temp_train, temp_test = train_test_split(a, test_size=0.3, random_state=42)\n",
    "    normal_train.append(temp_train)\n",
    "    normal_test.append(temp_test)\n",
    "\n",
    "    temp_train, temp_test = train_test_split(b, test_size=0.3, random_state=42)\n",
    "    botnet_train.append(temp_train)\n",
    "    botnet_test.append(temp_test)\n",
    "\n",
    "    temp_train, temp_test = train_test_split(c, test_size=0.3, random_state=42)\n",
    "    botnet_spam_train.append(temp_train)\n",
    "    botnet_spam_test.append(temp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining training data into one\n",
    "temp_train_df = []\n",
    "for a, b, c in zip(normal_train, botnet_train, botnet_spam_train):\n",
    "    temp_train_df.append(pd.concat([a, b, c], ignore_index=True))\n",
    "train_df = pd.concat(temp_train_df, ignore_index=True)\n",
    "\n",
    "# combining test data for each \n",
    "test_df = []\n",
    "for a, b, c in zip(normal_test, botnet_test, botnet_spam_test):\n",
    "    test_df.append(pd.concat([a, b, c], ignore_index=True))\n",
    "\n",
    "# Shuffle the combined training and testing datasets\n",
    "train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "for index in range(len(test_df)):\n",
    "    test_df[index] = test_df[index].sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('final_dataset/train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = ['1', '2', '3']\n",
    "for a, b in zip(test_df, filenames):\n",
    "    a.to_csv(f'final_dataset/test_{b}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
